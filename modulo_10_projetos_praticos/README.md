# M√≥dulo 10: Projetos Pr√°ticos

## üéØ Objetivos do M√≥dulo

Ao final deste m√≥dulo, voc√™ ser√° capaz de:
- Desenvolver projetos completos end-to-end de NLP
- Criar APIs REST para modelos de NLP
- Implementar interfaces web para sistemas de NLP
- Deploar modelos em produ√ß√£o
- Monitorar performance de modelos
- Construir portf√≥lio profissional de NLP

## üöÄ Projetos Principais

### Projeto 1: Sistema de An√°lise de Sentimentos para E-commerce

#### 1.1 Descri√ß√£o
Sistema completo para analisar sentimentos em reviews de produtos, incluindo:
- Coleta de dados via web scraping
- Pr√©-processamento e limpeza
- Treinamento de modelos (BERT fine-tuned)
- API REST para predi√ß√µes
- Dashboard web interativo
- Deploy em cloud (AWS/GCP)

#### 1.2 Arquitetura
```
Data Collection ‚Üí Data Processing ‚Üí Model Training ‚Üí API ‚Üí Frontend ‚Üí Deploy
      ‚Üì               ‚Üì               ‚Üì           ‚Üì        ‚Üì         ‚Üì
   Scrapy/BeautifulSoup ‚Üí Pandas/NLTK ‚Üí Transformers ‚Üí FastAPI ‚Üí Streamlit ‚Üí Docker/K8s
```

#### 1.3 Funcionalidades
- **An√°lise em tempo real** de reviews
- **Classifica√ß√£o multi-classe** (1-5 estrelas)
- **Extra√ß√£o de aspectos** (pre√ßo, qualidade, entrega)
- **Visualiza√ß√µes interativas**
- **Relat√≥rios automatizados**
- **Sistema de alertas**

#### 1.4 Stack Tecnol√≥gico
```python
# Backend
fastapi==0.104.1
transformers==4.35.0
torch==2.1.0
pandas==2.1.3
scikit-learn==1.3.2

# Frontend  
streamlit==1.28.2
plotly==5.17.0
altair==5.1.2

# Deploy
docker==6.1.3
kubernetes==28.1.0
mlflow==2.8.1
```

### Projeto 2: Chatbot Inteligente para Atendimento

#### 2.1 Descri√ß√£o
Chatbot conversacional para atendimento ao cliente com:
- Compreens√£o de inten√ß√µes (NLU)
- Extra√ß√£o de entidades
- Gera√ß√£o de respostas contextuais
- Integra√ß√£o com knowledge base
- Handoff para humanos
- Analytics de conversas

#### 2.2 Componentes

**Natural Language Understanding:**
```python
# Intent Classification
user_input: "Quero cancelar meu pedido"
intent: "cancel_order"
confidence: 0.95

# Entity Extraction  
entities: {
    "order_id": "12345",
    "reason": "mudan√ßa de endere√ßo"
}
```

**Dialogue Management:**
- State tracking
- Context management
- Flow control
- Escalation rules

**Response Generation:**
- Template-based for structured responses
- Neural generation for open-domain
- Personality consistency

#### 2.3 Tecnologias
- **Rasa** para framework de chatbot
- **spaCy** para NER
- **BERT** para intent classification
- **GPT** para response generation
- **Redis** para session management
- **PostgreSQL** para conversation logs

### Projeto 3: Sistema de Busca Sem√¢ntica

#### 3.1 Descri√ß√£o
Sistema de busca que entende significado, n√£o apenas palavras-chave:
- Indexa√ß√£o sem√¢ntica de documentos
- Busca por similaridade vetorial
- Re-ranking neural
- Interface de pesquisa avan√ßada
- Explicabilidade de resultados

#### 3.2 Pipeline de Busca
```
Query ‚Üí Embedding ‚Üí Vector Search ‚Üí Re-ranking ‚Üí Results
  ‚Üì         ‚Üì           ‚Üì            ‚Üì          ‚Üì
User ‚Üí BERT/SBERT ‚Üí Elasticsearch ‚Üí Cross-encoder ‚Üí UI
```

#### 3.3 Caracter√≠sticas Avan√ßadas
- **Busca multimodal** (texto + imagens)
- **Filtros facetados**
- **Autocomplete sem√¢ntico**
- **Clustering de resultados**
- **Feedback learning**

#### 3.4 Implementa√ß√£o
```python
# Vector Store
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

class SemanticSearch:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.encoder = SentenceTransformer(model_name)
        self.index = None
        self.documents = []
    
    def index_documents(self, docs):
        embeddings = self.encoder.encode(docs)
        self.index = faiss.IndexFlatIP(embeddings.shape[1])
        self.index.add(embeddings.astype('float32'))
        self.documents = docs
    
    def search(self, query, k=10):
        query_embedding = self.encoder.encode([query])
        scores, indices = self.index.search(query_embedding.astype('float32'), k)
        return [(self.documents[i], scores[0][j]) 
                for j, i in enumerate(indices[0])]
```

### Projeto 4: Sumarizador de Not√≠cias Autom√°tico

#### 4.1 Descri√ß√£o
Sistema que monitora fontes de not√≠cias e gera sum√°rios autom√°ticos:
- RSS feed monitoring
- Deduplica√ß√£o de not√≠cias
- Sumariza√ß√£o extractiva e abstractiva
- Categoriza√ß√£o autom√°tica
- Newsletter personalizado
- Trend detection

#### 4.2 Arquitetura
```
RSS Feeds ‚Üí Article Extraction ‚Üí Deduplication ‚Üí Summarization ‚Üí Categorization ‚Üí Distribution
    ‚Üì              ‚Üì               ‚Üì              ‚Üì              ‚Üì              ‚Üì
 feedparser ‚Üí newspaper3k ‚Üí MinHash ‚Üí BART/T5 ‚Üí BERT ‚Üí Email/Web
```

#### 4.3 Funcionalidades
- **Multi-document summarization**
- **Timeline construction**
- **Bias detection**
- **Fact checking integration**
- **Personalized summaries**

### Projeto 5: Detector de Fake News

#### 5.1 Descri√ß√£o
Sistema para identificar not√≠cias falsas usando:
- An√°lise lingu√≠stica (estilo, complexidade)
- Verifica√ß√£o de fontes
- Cross-referencing
- Network analysis
- Machine learning ensemble

#### 5.2 Features de Detec√ß√£o

**Lingu√≠sticas:**
- Sentiment analysis
- Readability scores
- POS tag patterns
- Named entity consistency

**Estruturais:**
- Source credibility
- Publication patterns
- Social media signals
- Link analysis

**Contextuais:**
- Fact database lookup
- Claim verification
- Expert network consensus

#### 5.3 Modelo Ensemble
```python
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Ensemble de diferentes tipos de features
ensemble = VotingClassifier([
    ('linguistic', LogisticRegression()),
    ('structural', RandomForestClassifier()),
    ('contextual', XGBClassifier())
], voting='soft')
```

## üõ† Infraestrutura e Deploy

### 1. Containeriza√ß√£o com Docker

```dockerfile
# Dockerfile para API de NLP
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 2. Orquestra√ß√£o com Kubernetes

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nlp-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nlp-api
  template:
    metadata:
      labels:
        app: nlp-api
    spec:
      containers:
      - name: nlp-api
        image: nlp-api:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
```

### 3. Monitoramento e Observabilidade

**MLflow para Model Tracking:**
```python
import mlflow
import mlflow.transformers

with mlflow.start_run():
    mlflow.log_param("learning_rate", 2e-5)
    mlflow.log_param("batch_size", 16)
    mlflow.log_metric("accuracy", 0.94)
    mlflow.transformers.log_model(model, "bert-classifier")
```

**Prometheus + Grafana para Monitoring:**
- Request latency
- Model accuracy drift
- Resource utilization
- Error rates

### 4. CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy NLP API
on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Run tests
      run: |
        pip install -r requirements.txt
        pytest tests/
  
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - name: Build and push Docker image
      run: |
        docker build -t nlp-api:${{ github.sha }} .
        docker push nlp-api:${{ github.sha }}
    
    - name: Deploy to Kubernetes
      run: |
        kubectl set image deployment/nlp-api nlp-api=nlp-api:${{ github.sha }}
```

## üìä Avalia√ß√£o e M√©tricas

### 1. M√©tricas T√©cnicas
- **Model Performance**: Accuracy, F1, BLEU, ROUGE
- **Latency**: Response time < 100ms
- **Throughput**: Requests per second
- **Scalability**: Load testing results

### 2. M√©tricas de Neg√≥cio
- **User Satisfaction**: Feedback scores
- **Task Completion Rate**: Success metrics
- **Cost Efficiency**: Infrastructure costs
- **ROI**: Return on investment

### 3. M√©tricas de Qualidade
- **Code Coverage**: >80%
- **Documentation**: Complete API docs
- **Security**: Vulnerability scanning
- **Compliance**: Data privacy adherence

## üéì Certifica√ß√£o e Portfolio

### 1. Documenta√ß√£o de Projetos
Cada projeto deve incluir:
- **README completo** com setup instructions
- **Architecture documentation**
- **API documentation** (Swagger/OpenAPI)
- **Performance benchmarks**
- **Deployment guide**

### 2. Apresenta√ß√£o de Resultados
- **Technical blog posts**
- **Video demonstrations**
- **GitHub repositories**
- **Live deployments**
- **Case studies**

### 3. Portfolio Website
```html
<!DOCTYPE html>
<html>
<head>
    <title>NLP Portfolio - [Seu Nome]</title>
</head>
<body>
    <h1>Projetos de NLP</h1>
    <div class="project">
        <h2>Sistema de An√°lise de Sentimentos</h2>
        <p>Sistema completo para e-commerce com BERT...</p>
        <a href="https://github.com/user/sentiment-analysis">GitHub</a>
        <a href="https://sentiment-demo.herokuapp.com">Demo</a>
    </div>
    <!-- Mais projetos... -->
</body>
</html>
```

## üéØ Pr√≥ximos Passos na Carreira

### 1. Especializa√ß√µes Avan√ßadas
- **Computer Vision + NLP** (Multimodal AI)
- **Speech Processing** (ASR, TTS)
- **Reinforcement Learning** for NLP
- **Quantum Computing** applications

### 2. √Åreas de Aplica√ß√£o
- **Healthcare**: Medical text mining
- **Finance**: Document analysis, fraud detection
- **Legal**: Contract analysis, case law
- **Education**: Automated grading, tutoring

### 3. Posi√ß√µes Profissionais
- **NLP Engineer**
- **Data Scientist** (NLP focus)
- **AI Researcher**
- **Technical Lead**
- **ML Engineer**

---

## üìù Checklist Final do Curso

- [ ] Completar todos os 10 m√≥dulos
- [ ] Implementar pelo menos 3 projetos completos
- [ ] Criar portfolio online
- [ ] Deploy pelo menos 1 projeto em produ√ß√£o
- [ ] Documentar todas as implementa√ß√µes
- [ ] Preparar apresenta√ß√£o final
- [ ] Solicitar certificado de conclus√£o

**üéâ Parab√©ns! Voc√™ completou o curso completo de NLP do b√°sico ao avan√ßado!**

---

**Dica**: Execute o notebook `10_projetos_praticos.ipynb` para templates de todos os projetos! 