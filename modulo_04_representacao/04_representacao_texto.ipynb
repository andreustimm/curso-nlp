{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Módulo 4: Representação de Texto\n",
        "\n",
        "## 🎯 Objetivos\n",
        "- Implementar Bag of Words e suas variações\n",
        "- Calcular e interpretar TF-IDF\n",
        "- Treinar word embeddings (Word2Vec, FastText)\n",
        "- Aplicar redução de dimensionalidade\n",
        "- Comparar diferentes representações vetoriais\n",
        "\n",
        "## 🛠 Técnicas Implementadas\n",
        "1. **Bag of Words (BoW)** - Binary, Count, Normalized\n",
        "2. **TF-IDF** - Term Frequency × Inverse Document Frequency  \n",
        "3. **Word Embeddings** - Word2Vec, FastText, GloVe\n",
        "4. **Redução de Dimensionalidade** - PCA, t-SNE, UMAP\n",
        "5. **Avaliação de Representações** - Similaridade, analogias\n",
        "6. **Aplicações Práticas** - Busca semântica, clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importações para representação de texto\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Word Embeddings\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "# Visualização\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Datasets\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from datasets.textos_exemplo import *\n",
        "from utils.nlp_utils import *\n",
        "\n",
        "print(\"🔤 Bibliotecas para representação de texto carregadas!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎒 1. Bag of Words (BoW) - Implementação Completa\n",
        "\n",
        "Vamos implementar e comparar diferentes variações do Bag of Words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar dados para representação\n",
        "corpus_pequeno = [\n",
        "    \"O gato subiu no telhado\",\n",
        "    \"O cachorro correu no parque\", \n",
        "    \"O gato desceu do telhado\",\n",
        "    \"O cachorro brincou no parque com outros cachorros\",\n",
        "    \"Os gatos e cachorros são animais domésticos\"\n",
        "]\n",
        "\n",
        "print(\"📝 Corpus de exemplo:\")\n",
        "for i, doc in enumerate(corpus_pequeno):\n",
        "    print(f\"{i+1}. {doc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# 1. Bag of Words Binário\n",
        "print(\"🎒 1. Bag of Words BINÁRIO\")\n",
        "bow_binary = CountVectorizer(binary=True, lowercase=True)\n",
        "bow_binary_matrix = bow_binary.fit_transform(corpus_pequeno)\n",
        "\n",
        "# 2. Bag of Words por Contagem\n",
        "print(\"\\n🎒 2. Bag of Words por CONTAGEM\")\n",
        "bow_count = CountVectorizer(binary=False, lowercase=True)\n",
        "bow_count_matrix = bow_count.fit_transform(corpus_pequeno)\n",
        "\n",
        "# 3. TF-IDF\n",
        "print(\"\\n🎒 3. TF-IDF\")\n",
        "tfidf = TfidfVectorizer(lowercase=True)\n",
        "tfidf_matrix = tfidf.fit_transform(corpus_pequeno)\n",
        "\n",
        "# Função para mostrar matriz de forma legível\n",
        "def mostrar_matriz(matrix, vectorizer, titulo, top_features=10):\n",
        "    print(f\"\\n{titulo}\")\n",
        "    print(\"-\" * len(titulo))\n",
        "    \n",
        "    # Obter nomes das features\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    \n",
        "    # Converter para array denso\n",
        "    dense_matrix = matrix.toarray()\n",
        "    \n",
        "    # Criar DataFrame para visualização\n",
        "    df = pd.DataFrame(dense_matrix, \n",
        "                      columns=feature_names,\n",
        "                      index=[f\"Doc {i+1}\" for i in range(len(corpus_pequeno))])\n",
        "    \n",
        "    print(f\"📊 Dimensões: {matrix.shape[0]} documentos × {matrix.shape[1]} features\")\n",
        "    print(f\"🔍 Esparsidade: {(1.0 - matrix.nnz / (matrix.shape[0] * matrix.shape[1])):.3f}\")\n",
        "    \n",
        "    # Mostrar apenas as top features para visualização\n",
        "    if len(feature_names) > top_features:\n",
        "        # Selecionar features com maior variância\n",
        "        feature_variance = np.var(dense_matrix, axis=0)\n",
        "        top_indices = np.argsort(feature_variance)[-top_features:]\n",
        "        df_subset = df.iloc[:, top_indices]\n",
        "        print(f\"\\n📋 Top {top_features} features (por variância):\")\n",
        "        print(df_subset.round(3))\n",
        "    else:\n",
        "        print(f\"\\n📋 Todas as features:\")\n",
        "        print(df.round(3))\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Mostrar as três representações\n",
        "df_binary = mostrar_matriz(bow_binary_matrix, bow_binary, \"🎒 MATRIZ BINÁRIA\", 8)\n",
        "df_count = mostrar_matriz(bow_count_matrix, bow_count, \"🎒 MATRIZ DE CONTAGEM\", 8)  \n",
        "df_tfidf = mostrar_matriz(tfidf_matrix, tfidf, \"🎒 MATRIZ TF-IDF\", 8)\n",
        "\n",
        "# Comparar esparsidade\n",
        "print(f\"\\n📊 COMPARAÇÃO DE ESPARSIDADE:\")\n",
        "print(f\"Binary BoW: {(1.0 - bow_binary_matrix.nnz / (bow_binary_matrix.shape[0] * bow_binary_matrix.shape[1])):.3f}\")\n",
        "print(f\"Count BoW:  {(1.0 - bow_count_matrix.nnz / (bow_count_matrix.shape[0] * bow_count_matrix.shape[1])):.3f}\")\n",
        "print(f\"TF-IDF:     {(1.0 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])):.3f}\")\n",
        "\n",
        "# Análise das palavras mais importantes no TF-IDF\n",
        "print(f\"\\n🔝 PALAVRAS COM MAIOR TF-IDF MÉDIO:\")\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "mean_tfidf = np.mean(tfidf_matrix.toarray(), axis=0)\n",
        "top_indices = np.argsort(mean_tfidf)[-10:]\n",
        "\n",
        "for idx in reversed(top_indices):\n",
        "    print(f\"{feature_names[idx]:12}: {mean_tfidf[idx]:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
