{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# MÃ³dulo 4: RepresentaÃ§Ã£o de Texto\n",
        "\n",
        "## ğŸ¯ Objetivos\n",
        "- Implementar Bag of Words e suas variaÃ§Ãµes\n",
        "- Calcular e interpretar TF-IDF\n",
        "- Treinar word embeddings (Word2Vec, FastText)\n",
        "- Aplicar reduÃ§Ã£o de dimensionalidade\n",
        "- Comparar diferentes representaÃ§Ãµes vetoriais\n",
        "\n",
        "## ğŸ›  TÃ©cnicas Implementadas\n",
        "1. **Bag of Words (BoW)** - Binary, Count, Normalized\n",
        "2. **TF-IDF** - Term Frequency Ã— Inverse Document Frequency  \n",
        "3. **Word Embeddings** - Word2Vec, FastText, GloVe\n",
        "4. **ReduÃ§Ã£o de Dimensionalidade** - PCA, t-SNE, UMAP\n",
        "5. **AvaliaÃ§Ã£o de RepresentaÃ§Ãµes** - Similaridade, analogias\n",
        "6. **AplicaÃ§Ãµes PrÃ¡ticas** - Busca semÃ¢ntica, clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ImportaÃ§Ãµes para representaÃ§Ã£o de texto\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Word Embeddings\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "# VisualizaÃ§Ã£o\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Datasets\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from datasets.textos_exemplo import *\n",
        "from utils.nlp_utils import *\n",
        "\n",
        "print(\"ğŸ”¤ Bibliotecas para representaÃ§Ã£o de texto carregadas!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ’ 1. Bag of Words (BoW) - ImplementaÃ§Ã£o Completa\n",
        "\n",
        "Vamos implementar e comparar diferentes variaÃ§Ãµes do Bag of Words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar dados para representaÃ§Ã£o\n",
        "corpus_pequeno = [\n",
        "    \"O gato subiu no telhado\",\n",
        "    \"O cachorro correu no parque\", \n",
        "    \"O gato desceu do telhado\",\n",
        "    \"O cachorro brincou no parque com outros cachorros\",\n",
        "    \"Os gatos e cachorros sÃ£o animais domÃ©sticos\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ“ Corpus de exemplo:\")\n",
        "for i, doc in enumerate(corpus_pequeno):\n",
        "    print(f\"{i+1}. {doc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# 1. Bag of Words BinÃ¡rio\n",
        "print(\"ğŸ’ 1. Bag of Words BINÃRIO\")\n",
        "bow_binary = CountVectorizer(binary=True, lowercase=True)\n",
        "bow_binary_matrix = bow_binary.fit_transform(corpus_pequeno)\n",
        "\n",
        "# 2. Bag of Words por Contagem\n",
        "print(\"\\nğŸ’ 2. Bag of Words por CONTAGEM\")\n",
        "bow_count = CountVectorizer(binary=False, lowercase=True)\n",
        "bow_count_matrix = bow_count.fit_transform(corpus_pequeno)\n",
        "\n",
        "# 3. TF-IDF\n",
        "print(\"\\nğŸ’ 3. TF-IDF\")\n",
        "tfidf = TfidfVectorizer(lowercase=True)\n",
        "tfidf_matrix = tfidf.fit_transform(corpus_pequeno)\n",
        "\n",
        "# FunÃ§Ã£o para mostrar matriz de forma legÃ­vel\n",
        "def mostrar_matriz(matrix, vectorizer, titulo, top_features=10):\n",
        "    print(f\"\\n{titulo}\")\n",
        "    print(\"-\" * len(titulo))\n",
        "    \n",
        "    # Obter nomes das features\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    \n",
        "    # Converter para array denso\n",
        "    dense_matrix = matrix.toarray()\n",
        "    \n",
        "    # Criar DataFrame para visualizaÃ§Ã£o\n",
        "    df = pd.DataFrame(dense_matrix, \n",
        "                      columns=feature_names,\n",
        "                      index=[f\"Doc {i+1}\" for i in range(len(corpus_pequeno))])\n",
        "    \n",
        "    print(f\"ğŸ“Š DimensÃµes: {matrix.shape[0]} documentos Ã— {matrix.shape[1]} features\")\n",
        "    print(f\"ğŸ” Esparsidade: {(1.0 - matrix.nnz / (matrix.shape[0] * matrix.shape[1])):.3f}\")\n",
        "    \n",
        "    # Mostrar apenas as top features para visualizaÃ§Ã£o\n",
        "    if len(feature_names) > top_features:\n",
        "        # Selecionar features com maior variÃ¢ncia\n",
        "        feature_variance = np.var(dense_matrix, axis=0)\n",
        "        top_indices = np.argsort(feature_variance)[-top_features:]\n",
        "        df_subset = df.iloc[:, top_indices]\n",
        "        print(f\"\\nğŸ“‹ Top {top_features} features (por variÃ¢ncia):\")\n",
        "        print(df_subset.round(3))\n",
        "    else:\n",
        "        print(f\"\\nğŸ“‹ Todas as features:\")\n",
        "        print(df.round(3))\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Mostrar as trÃªs representaÃ§Ãµes\n",
        "df_binary = mostrar_matriz(bow_binary_matrix, bow_binary, \"ğŸ’ MATRIZ BINÃRIA\", 8)\n",
        "df_count = mostrar_matriz(bow_count_matrix, bow_count, \"ğŸ’ MATRIZ DE CONTAGEM\", 8)  \n",
        "df_tfidf = mostrar_matriz(tfidf_matrix, tfidf, \"ğŸ’ MATRIZ TF-IDF\", 8)\n",
        "\n",
        "# Comparar esparsidade\n",
        "print(f\"\\nğŸ“Š COMPARAÃ‡ÃƒO DE ESPARSIDADE:\")\n",
        "print(f\"Binary BoW: {(1.0 - bow_binary_matrix.nnz / (bow_binary_matrix.shape[0] * bow_binary_matrix.shape[1])):.3f}\")\n",
        "print(f\"Count BoW:  {(1.0 - bow_count_matrix.nnz / (bow_count_matrix.shape[0] * bow_count_matrix.shape[1])):.3f}\")\n",
        "print(f\"TF-IDF:     {(1.0 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])):.3f}\")\n",
        "\n",
        "# AnÃ¡lise das palavras mais importantes no TF-IDF\n",
        "print(f\"\\nğŸ” PALAVRAS COM MAIOR TF-IDF MÃ‰DIO:\")\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "mean_tfidf = np.mean(tfidf_matrix.toarray(), axis=0)\n",
        "top_indices = np.argsort(mean_tfidf)[-10:]\n",
        "\n",
        "for idx in reversed(top_indices):\n",
        "    print(f\"{feature_names[idx]:12}: {mean_tfidf[idx]:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
