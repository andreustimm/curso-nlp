{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# M칩dulo 9: Tarefas Avan칞adas de NLP\n",
        "\n",
        "## 游꿢 Objetivos\n",
        "- Implementar sistemas de Question Answering\n",
        "- Construir modelos de sumariza칞칚o autom치tica\n",
        "- Desenvolver sistemas de tradu칞칚o neural\n",
        "- Aplicar an치lise de t칩picos (LDA)\n",
        "- Criar chatbots inteligentes\n",
        "- Implementar an치lise de documentos\n",
        "\n",
        "## 游꿑 Tarefas Avan칞adas\n",
        "1. **Question Answering** - Extractivo e generativo\n",
        "2. **Sumariza칞칚o** - Extractiva e abstractiva\n",
        "3. **Tradu칞칚o Neural** - Seq2Seq, Transformer\n",
        "4. **Topic Modeling** - LDA, BERTopic\n",
        "5. **Chatbots** - Intent classification, NLU\n",
        "6. **Document Analysis** - Classifica칞칚o, extra칞칚o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa칞칫es para tarefas avan칞adas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Transformers para tarefas espec칤ficas\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "    BertForQuestionAnswering, BertTokenizer,\n",
        "    BartForConditionalGeneration, BartTokenizer,\n",
        "    MarianMTModel, MarianTokenizer,\n",
        "    T5ForConditionalGeneration, T5Tokenizer\n",
        ")\n",
        "\n",
        "# Topic Modeling\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Sumariza칞칚o\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer as SumyTokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "\n",
        "# Similaridade e clustering\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Visualiza칞칚o\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# NLP b치sico\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Datasets\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from datasets.textos_exemplo import *\n",
        "from utils.nlp_utils import *\n",
        "\n",
        "print(\"游꿑 Bibliotecas para tarefas avan칞adas carregadas!\")\n",
        "print(\"游늵 Pipelines dispon칤veis: QA, Sumariza칞칚o, Tradu칞칚o, An치lise de T칩picos\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
