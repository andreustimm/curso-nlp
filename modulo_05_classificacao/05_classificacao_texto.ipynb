{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# M√≥dulo 5: Classifica√ß√£o de Texto\n",
        "\n",
        "## üéØ Objetivos\n",
        "- Implementar algoritmos cl√°ssicos de classifica√ß√£o\n",
        "- Aplicar Naive Bayes, SVM e Regress√£o Log√≠stica\n",
        "- Usar ensemble methods\n",
        "- Avaliar modelos com m√©tricas adequadas\n",
        "- Lidar com dados desbalanceados\n",
        "- Otimizar hiperpar√¢metros\n",
        "\n",
        "## ü§ñ Algoritmos Implementados\n",
        "1. **Naive Bayes** - Multinomial, Bernoulli, Gaussian\n",
        "2. **SVM** - Support Vector Machines com diferentes kernels\n",
        "3. **Regress√£o Log√≠stica** - Com regulariza√ß√£o L1/L2\n",
        "4. **Ensemble Methods** - Random Forest, Voting, Boosting\n",
        "5. **Otimiza√ß√£o** - Grid Search, Cross-validation\n",
        "6. **Dados Desbalanceados** - SMOTE, class weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa√ß√µes para classifica√ß√£o de texto\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                           classification_report, confusion_matrix, roc_auc_score)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Dados desbalanceados\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Visualiza√ß√£o\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Datasets\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from datasets.textos_exemplo import *\n",
        "from utils.nlp_utils import *\n",
        "\n",
        "print(\"üéØ Bibliotecas para classifica√ß√£o carregadas!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ 1. Classifica√ß√£o de Sentimentos - Projeto Completo\n",
        "\n",
        "Vamos implementar um classificador de sentimentos comparando m√∫ltiplos algoritmos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar dataset sint√©tico de an√°lise de sentimentos\n",
        "np.random.seed(42)\n",
        "\n",
        "# Reviews positivos\n",
        "reviews_positivos = [\n",
        "    \"Excelente produto, recomendo muito!\",\n",
        "    \"Adorei a qualidade, superou minhas expectativas.\",\n",
        "    \"Muito bom, chegou r√°pido e bem embalado.\",\n",
        "    \"Produto incr√≠vel, vale cada centavo!\",\n",
        "    \"Estou muito satisfeito com a compra.\",\n",
        "    \"Qualidade excepcional, comprarei novamente.\",\n",
        "    \"Fant√°stico! Melhor que imaginava.\",\n",
        "    \"Produto maravilhoso, entrega r√°pida.\",\n",
        "    \"Simplesmente perfeito, recomendo a todos.\",\n",
        "    \"Excelente custo-benef√≠cio, muito bom produto.\"\n",
        "]\n",
        "\n",
        "# Reviews negativos  \n",
        "reviews_negativos = [\n",
        "    \"Produto terr√≠vel, n√£o recomendo.\",\n",
        "    \"Muito ruim, dinheiro jogado fora.\",\n",
        "    \"Qualidade p√©ssima, chegou quebrado.\",\n",
        "    \"Horr√≠vel, n√£o serve para nada.\",\n",
        "    \"Decepcionante, esperava muito mais.\",\n",
        "    \"Produto de baixa qualidade, muito caro.\",\n",
        "    \"N√£o gostei, vou devolver.\",\n",
        "    \"P√©ssimo atendimento e produto ruim.\",\n",
        "    \"N√£o vale o pre√ßo, muito caro para pouca qualidade.\",\n",
        "    \"Produto defeituoso, n√£o funcionou.\"\n",
        "]\n",
        "\n",
        "# Criar dataset\n",
        "X = reviews_positivos + reviews_negativos\n",
        "y = ['positivo'] * len(reviews_positivos) + ['negativo'] * len(reviews_negativos)\n",
        "\n",
        "# Adicionar dados dos nossos textos de exemplo\n",
        "X.extend(textos_reviews)\n",
        "# Simular labels para os reviews (baseado em palavras-chave simples)\n",
        "for review in textos_reviews:\n",
        "    palavras_positivas = ['bom', '√≥timo', 'excelente', 'recomendo', 'gostei', 'perfeito']\n",
        "    palavras_negativas = ['ruim', 'p√©ssimo', 'horr√≠vel', 'terr√≠vel', 'n√£o gostei', 'decepcionante']\n",
        "    \n",
        "    review_lower = review.lower()\n",
        "    score_pos = sum(1 for palavra in palavras_positivas if palavra in review_lower)\n",
        "    score_neg = sum(1 for palavra in palavras_negativas if palavra in review_lower)\n",
        "    \n",
        "    if score_pos > score_neg:\n",
        "        y.append('positivo')\n",
        "    else:\n",
        "        y.append('negativo')\n",
        "\n",
        "print(f\"üìä Dataset criado:\")\n",
        "print(f\"Total de exemplos: {len(X)}\")\n",
        "print(f\"Positivos: {y.count('positivo')}\")\n",
        "print(f\"Negativos: {y.count('negativo')}\")\n",
        "\n",
        "# Exemplos do dataset\n",
        "print(f\"\\nüìù Exemplos do dataset:\")\n",
        "for i in range(5):\n",
        "    print(f\"{y[i]:10}: {X[i][:50]}...\")\n",
        "\n",
        "# Divis√£o treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nüîÄ Divis√£o dos dados:\")\n",
        "print(f\"Treino: {len(X_train)} exemplos\")\n",
        "print(f\"Teste:  {len(X_test)} exemplos\")\n",
        "\n",
        "# Fun√ß√£o para avaliar modelo\n",
        "def avaliar_modelo(name, model, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Avalia um modelo de classifica√ß√£o\"\"\"\n",
        "    \n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "    \n",
        "    # Predizer\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    pred_time = time.time() - start_time\n",
        "    \n",
        "    # M√©tricas\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, pos_label='positivo')\n",
        "    recall = recall_score(y_test, y_pred, pos_label='positivo')\n",
        "    f1 = f1_score(y_test, y_pred, pos_label='positivo')\n",
        "    \n",
        "    print(f\"\\nüìä {name}\")\n",
        "    print(\"-\" * (len(name) + 4))\n",
        "    print(f\"Accuracy:  {accuracy:.3f}\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall:    {recall:.3f}\")\n",
        "    print(f\"F1-Score:  {f1:.3f}\")\n",
        "    print(f\"Tempo treino: {train_time:.3f}s\")\n",
        "    print(f\"Tempo pred:   {pred_time:.3f}s\")\n",
        "    \n",
        "    return {\n",
        "        'name': name,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'train_time': train_time,\n",
        "        'pred_time': pred_time,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "# Pipeline com diferentes algoritmos\n",
        "modelos = [\n",
        "    ('Naive Bayes', Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_features=1000)),\n",
        "        ('nb', MultinomialNB())\n",
        "    ])),\n",
        "    \n",
        "    ('SVM Linear', Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_features=1000)),\n",
        "        ('svm', SVC(kernel='linear', random_state=42))\n",
        "    ])),\n",
        "    \n",
        "    ('Logistic Regression', Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_features=1000)),\n",
        "        ('lr', LogisticRegression(random_state=42))\n",
        "    ])),\n",
        "    \n",
        "    ('Random Forest', Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_features=1000)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ]))\n",
        "]\n",
        "\n",
        "# Avaliar todos os modelos\n",
        "resultados = []\n",
        "for nome, modelo in modelos:\n",
        "    resultado = avaliar_modelo(nome, modelo, X_train, X_test, y_train, y_test)\n",
        "    resultados.append(resultado)\n",
        "\n",
        "# Comparar resultados\n",
        "print(f\"\\nüèÜ COMPARA√á√ÉO DOS MODELOS:\")\n",
        "print(\"=\" * 70)\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(df_resultados[['name', 'accuracy', 'f1', 'train_time']].round(3))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
