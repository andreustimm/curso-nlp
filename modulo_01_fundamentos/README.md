[‚¨ÖÔ∏è Voltar para o √≠ndice do curso](../README.md)

# M√≥dulo 1: Fundamentos de NLP

## üéØ Objetivos do M√≥dulo

Ao final deste m√≥dulo, voc√™ ser√° capaz de:
- Compreender o que √© Processamento de Linguagem Natural
- Conhecer a hist√≥ria e evolu√ß√£o do NLP
- Identificar as principais aplica√ß√µes do NLP
- Entender os desafios fundamentais do processamento de linguagem
- Conhecer o pipeline b√°sico de um sistema de NLP

## üìö Conte√∫do Te√≥rico

### 1. O que √© NLP?

O **Processamento de Linguagem Natural (NLP)** √© uma sub√°rea da Intelig√™ncia Artificial que combina ci√™ncia da computa√ß√£o, lingu√≠stica e aprendizado de m√°quina para permitir que computadores compreendam, interpretem e gerem linguagem humana de forma √∫til.

### 2. Hist√≥ria do NLP

#### D√©cada de 1950-1960: Prim√≥rdios
- **1950**: Teste de Turing
- **1954**: Primeiro experimento de tradu√ß√£o autom√°tica (Georgetown-IBM)
- **1960s**: Sistemas baseados em regras

#### D√©cada de 1980-1990: Era Estat√≠stica
- **1980s**: Introdu√ß√£o de m√©todos estat√≠sticos
- **1990s**: Corpus linguistics e modelos probabil√≠sticos

#### D√©cada de 2000-2010: Machine Learning
- **2000s**: SVM, Naive Bayes para NLP
- **2003**: Word embeddings iniciais
- **2006**: Deep learning ressurge

#### D√©cada de 2010-presente: Deep Learning
- **2013**: Word2Vec
- **2017**: Transformer (Attention is All You Need)
- **2018**: BERT revoluciona o campo
- **2019-2023**: Era dos Large Language Models (GPT, ChatGPT)

### 3. Principais Aplica√ß√µes

#### Comunica√ß√£o e Tradu√ß√£o
- **Tradu√ß√£o Autom√°tica**: Google Translate, DeepL
- **Corre√ß√£o Ortogr√°fica**: Grammarly, corretor do Word
- **Assistentes Virtuais**: Siri, Alexa, Google Assistant

#### An√°lise de Texto
- **An√°lise de Sentimentos**: Monitoramento de redes sociais
- **Classifica√ß√£o de Documentos**: Organiza√ß√£o autom√°tica
- **Extra√ß√£o de Informa√ß√µes**: Named Entity Recognition

#### Gera√ß√£o de Conte√∫do
- **Chatbots**: Atendimento ao cliente
- **Sumariza√ß√£o**: Resumo autom√°tico de textos
- **Gera√ß√£o de Texto**: GPT, Claude, ChatGPT

#### Busca e Recupera√ß√£o
- **Motores de Busca**: Google, Bing
- **Sistemas de Recomenda√ß√£o**: Netflix, Amazon
- **Question Answering**: Sistemas de perguntas e respostas

### 4. Desafios Fundamentais do NLP

#### Ambiguidade
- **Lexical**: Uma palavra com m√∫ltiplos significados
  - "Banco" ‚Üí institui√ß√£o financeira ou assento
- **Sint√°tica**: Estrutura gramatical amb√≠gua
  - "Vi o homem com o telesc√≥pio"
- **Sem√¢ntica**: Significado amb√≠guo
  - "Ele foi ao banco" (contexto determina o significado)

#### Variabilidade Lingu√≠stica
- **Dialetos e Sotaques**: Varia√ß√µes regionais
- **G√≠rias e Neologismos**: Linguagem em constante evolu√ß√£o
- **Linguagem Informal**: Redes sociais, mensagens

#### Contexto e Pragm√°tica
- **Refer√™ncia**: "Ele chegou cedo" (quem √© "ele"?)
- **Ironia e Sarcasmo**: "Que dia lindo!" (em dia chuvoso)
- **Conhecimento de Mundo**: Informa√ß√µes impl√≠citas

#### Diversidade de Idiomas
- **Morfologia Rica**: Portugu√™s, alem√£o
- **Ordem de Palavras**: SOV vs SVO vs VSO
- **Sistemas de Escrita**: Latino, √°rabe, chin√™s

### 5. Pipeline B√°sico de NLP

```
Texto Bruto ‚Üí Pr√©-processamento ‚Üí An√°lise ‚Üí Modelagem ‚Üí Aplica√ß√£o
```

#### Etapa 1: Pr√©-processamento
- **Limpeza**: Remo√ß√£o de caracteres especiais
- **Tokeniza√ß√£o**: Divis√£o em palavras/tokens
- **Normaliza√ß√£o**: Padroniza√ß√£o do texto

#### Etapa 2: An√°lise Lingu√≠stica
- **An√°lise Lexical**: Identifica√ß√£o de palavras
- **An√°lise Sint√°tica**: Estrutura gramatical
- **An√°lise Sem√¢ntica**: Significado das palavras

#### Etapa 3: Representa√ß√£o
- **Vetoriza√ß√£o**: Convers√£o para n√∫meros
- **Embeddings**: Representa√ß√µes densas
- **Features**: Caracter√≠sticas relevantes

#### Etapa 4: Modelagem
- **Algoritmos de ML**: Classifica√ß√£o, clustering
- **Deep Learning**: Redes neurais
- **Pr√©-treinados**: BERT, GPT

#### Etapa 5: Aplica√ß√£o
- **Interface**: APIs, aplica√ß√µes web
- **Avalia√ß√£o**: M√©tricas de performance
- **Deploy**: Produ√ß√£o e monitoramento

## üõ† Ferramentas e Bibliotecas

### Python Libraries
- **NLTK**: Natural Language Toolkit
- **spaCy**: Industrial-strength NLP
- **Gensim**: Topic modeling
- **TextBlob**: Simplified text processing

### Deep Learning
- **TensorFlow/Keras**: Google's framework
- **PyTorch**: Facebook's framework
- **Transformers**: Hugging Face

### Visualiza√ß√£o
- **WordCloud**: Nuvens de palavras
- **Matplotlib/Seaborn**: Gr√°ficos
- **Plotly**: Visualiza√ß√µes interativas

## üìä M√©tricas de Avalia√ß√£o

### Classifica√ß√£o
- **Accuracy**: Taxa de acerto geral
- **Precision**: Precis√£o por classe
- **Recall**: Revoca√ß√£o por classe
- **F1-Score**: M√©dia harm√¥nica de precision e recall

### Gera√ß√£o de Texto
- **BLEU**: Bilingual Evaluation Understudy
- **ROUGE**: Recall-Oriented Understudy for Gisting Evaluation
- **Perplexity**: Medida de incerteza do modelo

### Embeddings
- **Cosine Similarity**: Similaridade entre vetores
- **Analogies**: Capacidade de resolver analogias
- **Clustering**: Qualidade dos agrupamentos

## üí° Exerc√≠cios Pr√°ticos

1. **Explora√ß√£o de Corpus**: Analise um conjunto de textos
2. **Pipeline Simples**: Implemente um pipeline b√°sico
3. **Compara√ß√£o de Ferramentas**: Compare NLTK vs spaCy
4. **An√°lise Explorat√≥ria**: Visualize caracter√≠sticas de texto

## üìñ Leituras Complementares

### Livros
- "Speech and Language Processing" - Jurafsky & Martin
- "Natural Language Processing with Python" - Steven Bird
- "Introduction to Information Retrieval" - Manning et al.

### Papers Fundamentais
- "Attention Is All You Need" (Transformer)
- "BERT: Pre-training of Deep Bidirectional Transformers"
- "Efficient Estimation of Word Representations in Vector Space" (Word2Vec)

### Recursos Online
- [NLP Course by Hugging Face](https://huggingface.co/course/)
- [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)
- [spaCy Documentation](https://spacy.io/)

## üéØ Pr√≥ximos Passos

No **M√≥dulo 2**, vamos mergulhar no pr√©-processamento de texto, aprendendo t√©cnicas essenciais como tokeniza√ß√£o, normaliza√ß√£o, stemming e lemmatiza√ß√£o.

---

**Dica**: Execute o notebook `01_fundamentos_nlp.ipynb` para ver os conceitos na pr√°tica!

[‚¨ÖÔ∏è Voltar para o √≠ndice do curso](../README.md) 